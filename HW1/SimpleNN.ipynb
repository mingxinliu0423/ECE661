{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn2lVW8QOzZT"
      },
      "source": [
        "### Code block 1: Package initialization\n",
        "Import required packages, do not change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FqW8TFgbOzZW"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import pytorch dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.modules.utils import _single, _pair, _triple\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_1uHFnOzZW"
      },
      "source": [
        "### Code block 2: Useful classes\n",
        "Customized implementation of [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear), do not change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "90q98wndOzZX"
      },
      "outputs": [],
      "source": [
        "class CONV(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1,\n",
        "                 bias=False, padding_mode='zeros'):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "        kernel_size = _pair(kernel_size)\n",
        "        stride = _pair(stride)\n",
        "        padding = _pair(padding)\n",
        "        dilation = _pair(dilation)\n",
        "        super(CONV, self).__init__(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
        "            groups, bias, padding_mode)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        # 'pytorch 2.0'\n",
        "        self.output = super().forward(input)\n",
        "        return self.output\n",
        "\n",
        "class FC(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "        super(FC, self).__init__(in_features, out_features, bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = F.linear(input, self.weight, self.bias)\n",
        "        return self.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZOx_mgxOzZX"
      },
      "source": [
        "## Lab 2\n",
        "\n",
        "### Code block 3: SimpleNN implementation\n",
        "\n",
        "Please follow the instructions in Lab 2(a) and fill in the code in the lines marked **Your code here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_syDnXBAOzZX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run on GPU...\n",
            "Forward pass successful\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Lab 2(a)\n",
        "Build the SimpleNN model by following Table 1\n",
        "\"\"\"\n",
        "\n",
        "# Create the neural network module: LeNet-5\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        # Layer definition\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5, stride=1, padding=2) #Your code here\n",
        "        self.conv2 = nn.Conv2d(16, 16, 3, stride=1, padding=2)    #Your code here\n",
        "        self.conv3 = nn.Conv2d(16, 32, 7, stride=1, padding=2)    #Your code here\n",
        "        self.fc1   = nn.Linear(288,32)    #Your code here\n",
        "        self.fc2   = nn.Linear(32, 10)    #Your code here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass computation\n",
        "        # Conv 1\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        # MaxPool\n",
        "        x = nn.functional.max_pool2d(x, 4, 2)\n",
        "        # Conv 2\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        # MaxPool\n",
        "        x = nn.functional.max_pool2d(x, 3, 2)\n",
        "        # Conv 3\n",
        "        x = nn.functional.relu(self.conv3(x))\n",
        "        # MaxPool\n",
        "        x = nn.functional.max_pool2d(x, 2, 2)\n",
        "        # Flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "        # FC 1\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        # FC 2\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# GPU check\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device =='cuda':\n",
        "    print(\"Run on GPU...\")\n",
        "else:\n",
        "    print(\"Run on CPU...\")\n",
        "\n",
        "# Model Definition\n",
        "net = SimpleNN()\n",
        "net = net.to(device)\n",
        "\n",
        "# Test forward pass\n",
        "data = torch.randn(5,3,32,32)\n",
        "data = data.to(device)\n",
        "# Forward pass \"data\" through \"net\" to get output \"out\"\n",
        "out = net(data)\n",
        "\n",
        "# Check output shape\n",
        "assert(out.detach().cpu().numpy().shape == (5,10))\n",
        "print(\"Forward pass successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_54xl0CVOzZY"
      },
      "source": [
        "### Code block 4: Shape observation\n",
        "Please follow the instructions in Lab 2(a) and fill in the code in the lines marked **Your code here**. Gather the printed results in Table 2 in your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UReJCihqOzZY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Lab 2(b)\n",
        "\"\"\"\n",
        "# Forward pass of a single image\n",
        "data = torch.randn(1,3,32,32).to(device)\n",
        "# Forward pass \"data\" through \"net\" to get output \"out\"\n",
        "out = net(data)\n",
        "\n",
        "# Iterate through all the CONV and FC layers of the model\n",
        "for name, module in net.named_modules():\n",
        "    if isinstance(module, CONV) or isinstance(module, FC):\n",
        "        # Get the input feature map of the module as a NumPy array\n",
        "        input = module.input.cuda().detach().cpu().numpy()\n",
        "        # Get the output feature map of the module as a NumPy array\n",
        "        output = module.output.cuda().detach().cpu().numpy()     #Your code here\n",
        "        # Get the weight of the module as a NumPy array\n",
        "        weight = module.weight.cuda().detach().cpu().numpy()     #Your code here\n",
        "        # Compute the number of parameters in the weight\n",
        "        num_Param = weight.size      #Your code here\n",
        "        # Compute the number of MACs in the layer\n",
        "        _, _, h, w = output.shape\n",
        "        num_MAC = module.kernel_size[0] * module.kernel_size[1] * module.in_channels * module.out_channels * h * w if isinstance(module, CONV) else module.in_features * module.out_features\n",
        "\n",
        "        print(f'{name:10} {str(input.shape):20} {str(output.shape):20} {str(weight.shape):20} {str(num_Param):10} {str(num_MAC):10}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7s7YBjxOzZY"
      },
      "source": [
        "## Lab 3 (Bonus)\n",
        "\n",
        "### Code block 5: Initial weight histogram\n",
        "Please follow the instructions in Lab 3(a) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wwCVMLIuOzZY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Lab 3(a)\n",
        "\"\"\"\n",
        "for name, module in net.named_modules():\n",
        "    if isinstance(module, CONV) or isinstance(module, FC):\n",
        "        # Get the weight of the module as a NumPy array\n",
        "        weight = module.weight.detach().cpu().numpy() \n",
        "\n",
        "        # Reshape for histogram\n",
        "        weight = weight.reshape(-1)\n",
        "        _ = plt.hist(weight, bins=20)\n",
        "        plt.title(\"Weight histogram of layer \"+name)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVTU_6JnOzZZ"
      },
      "source": [
        "### Code block 6: Gradient histogram\n",
        "Please follow the instructions in Lab 3(b) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcKcfrjTOzZZ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Lab 3(b)\n",
        "'''\n",
        "# Loss definition\n",
        "criterion = nn.MSELoss()\n",
        "# Random target\n",
        "target = torch.randn(1, 10).to(device)\n",
        "\n",
        "# Loss computation\n",
        "loss = criterion(output, target)\n",
        "# Backward pass for gradients\n",
        "     #Your code here\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "for name, module in net.named_modules():\n",
        "    if isinstance(module, CONV) or isinstance(module, FC):\n",
        "        # Get the gradient of the module as a NumPy array\n",
        "        gradient = \n",
        "\n",
        "        # Reshape for histogram\n",
        "        gradient = gradient.reshape(-1)\n",
        "        _ = plt.hist(gradient, bins=20)\n",
        "        plt.title(\"Gradient histogram of layer \"+name)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOQmlCX0OzZZ"
      },
      "source": [
        "### Code block 7: Zero initialization?\n",
        "Please follow the instructions in Lab 3(c) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPON1n_-OzZZ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Lab 3(c)\n",
        "'''\n",
        "# Set model weights to zero\n",
        "for name, module in net.named_modules():\n",
        "    if isinstance(module, CONV) or isinstance(module, FC):\n",
        "        # Set the weight of each module to all zero\n",
        "             #Your code here\n",
        "\n",
        "# Reset gradients\n",
        "net.zero_grad()\n",
        "\n",
        "# Forward and backward pass\n",
        "# Random data and target\n",
        "data = torch.randn(1,3,32,32).to(device)\n",
        "target = torch.randn(1, 10).to(device)\n",
        "\n",
        "# Forward pass\n",
        "out =      #Your code here\n",
        "# Loss computation\n",
        "loss =      #Your code here\n",
        "# Backward pass\n",
        "     #Your code here\n",
        "\n",
        "for name, module in net.named_modules():\n",
        "    if isinstance(module, CONV) or isinstance(module, FC):\n",
        "        # Get the gradient of the module as a NumPy array\n",
        "        gradient =      #Your code here\n",
        "\n",
        "        # Reshape for histogram\n",
        "        gradient = gradient.reshape(-1)\n",
        "        _ = plt.hist(gradient, bins=20)\n",
        "        plt.title(\"Gradient histogram of layer \"+name)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F258G5IAOzZZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
